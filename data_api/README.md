# Sentiment Analysis API - Data Science Module

## ğŸš€ Instalar dependÃªncias e rodar notebooks/APIs

### Ambiente Python
- Requer Python 3.11+
- Ambiente virtual recomendado (hÃ¡ um pronto em `tools/sentiment-env`)

```bash
# ativar ambiente existente
cd tools/sentiment-env
source bin/activate

# ou criar outro e instalar deps
pip install -r ../requirements.txt
```

### Rodar a API localmente
```bash
cd data_science
python sentiment_api.py   # API original
# ou
python enhanced_sentiment_api.py   # API enhanced
```
API: http://localhost:5000

### Treinar e executar notebooks
```bash
cd data_science/notebooks
jupyter notebook enhanced_model_training.ipynb
```
Execute todas as cÃ©lulas para gerar modelos em `data_science/models/enhanced/`.

## ğŸ¯ Overview

- **Model**: Logistic Regression with TF-IDF vectorization
- **Classes**: Positive, Neutral, Negative (with class balancing for negative detection)
- **API**: FastAPI with automatic documentation
- **Performance**: 88% accuracy, 96% negative recall

## ğŸ¤– Available Models

### Original Model (Default)
- **Algorithm**: TF-IDF + Logistic Regression
- **Features**: Text only
- **Accuracy**: ~88%
- **Use Case**: Basic sentiment analysis, compatibility

### Enhanced Model (Recommended)
- **Algorithm**: TF-IDF + Random Forest
- **Features**: Text + Rating (1-5) + Recommendation (Yes/No) + Text Length
- **Accuracy**: ~92% (4% improvement)
- **Use Case**: Advanced analysis with metadata, higher accuracy

## ğŸ“Š Model Comparison

| Feature | Original Model | Enhanced Model |
|---------|----------------|----------------|
| **Input Features** | Text only | Text + Rating + Recommendation |
| **Algorithm** | Logistic Regression | Random Forest |
| **Accuracy** | 88% | 92% |
| **Training Time** | Fast | Moderate |
| **Memory Usage** | Low | Moderate |
| **API Compatibility** | Full | Extended |

### When to Use Enhanced Model

The Enhanced Model provides better accuracy by incorporating:
- **Rating Score**: 1-5 star rating provides direct sentiment signal
- **Recommendation**: Binary feature (would recommend to friend)
- **Text Length**: Contextual information about review depth
- **Combined Analysis**: Multiple signals reduce ambiguity

**Best for**: Production deployments, critical business decisions, detailed analysis.

## ğŸš€ Running with Docker (Recommended)

The API is containerized and runs as part of the complete Docker Compose setup:

```bash
# From project root
sudo docker-compose up -d
```

API will be available at: http://localhost:5000

## ğŸ› ï¸ Local Development Setup

If you want to run the API locally for development:

### Prerequisites
- Python 3.11+
- Virtual environment (sentiment-env provided)

### Setup Environment

1. **Activate the provided virtual environment**
   ```bash
   cd tools/sentiment-env
   source bin/activate
   ```

2. **Install dependencies** (if needed)
   ```bash
   pip install -r ../requirements.txt
   ```

### Run the API Locally

```bash
cd data_science
python sentiment_api.py
```

API will start on: http://localhost:5000

## ğŸ§  Training the Enhanced Model

The Enhanced Model provides better accuracy by using multiple features. To train it:

### Prerequisites
- Processed dataset (`datasets/reviews_cleaned.json`) - generated by `sentiment_model.ipynb`
- Jupyter Notebook environment

### Training Steps

1. **Navigate to notebooks directory**
   ```bash
   cd notebooks
   ```

2. **Run the enhanced training notebook**
   ```bash
   jupyter notebook enhanced_model_training.ipynb
   ```

3. **Execute all cells** in the notebook to:
   - âœ… Load pre-processed data from `reviews_cleaned.json`
   - âœ… Create TF-IDF features from cleaned text
   - âœ… Add rating, recommendation, and text length features
   - âœ… Train Random Forest model with multi-feature approach
   - âœ… Compare performance vs original model
   - âœ… Save enhanced models to `models/enhanced/`

### Expected Results
- **Accuracy**: ~99% (26% improvement over original model)
- **Feature Importance**: Recommendation (30%), Rating (26%), Text features
- **Training Time**: ~5-10 minutes
- **Model Size**: ~50MB (larger than original)

### Enhanced Model Files
After training, these files will be created:
```
models/enhanced/
â”œâ”€â”€ tfidf_vectorizer.joblib      # TF-IDF for text
â”œâ”€â”€ rating_scaler.joblib         # Scaler for rating feature
â”œâ”€â”€ random_forest_model.joblib   # Trained Random Forest
â”œâ”€â”€ sentiment_mapping.json       # Class mappings
â””â”€â”€ model_metadata.json          # Model information
```

## ğŸ“Š Testando a API Python

ApÃ³s rodar `python sentiment_api.py` ou `python enhanced_sentiment_api.py`:

**Health Check:**
```bash
curl http://localhost:5000/health
```

**PrediÃ§Ã£o simples:**
```bash
curl -X POST http://localhost:5000/predict \
     -H "Content-Type: application/json" \
     -d '{"text": "esse produto e otimo"}'
```

**PrediÃ§Ã£o enhanced (se disponÃ­vel):**
```bash
curl -X POST http://localhost:5000/predict/enhanced \
     -H "Content-Type: application/json" \
     -d '{"text":"esse produto e otimo","rating":5,"recommend_to_friend":true}'
```

**DocumentaÃ§Ã£o interativa:**  
http://localhost:5000/docs

## ğŸ“ Directory Structure

```
data_science/
â”œâ”€â”€ models/                 # Trained models and metadata
â”‚   â”œâ”€â”€ tfidf_vectorizer.joblib
â”‚   â”œâ”€â”€ logistic_regression_model.joblib
â”‚   â”œâ”€â”€ sentiment_mapping.json
â”‚   â””â”€â”€ model_metadata.json
â”œâ”€â”€ datasets/              # Training data
â”‚   â”œâ”€â”€ reviews_cleaned.json
â”‚   â””â”€â”€ reviews.json
â”œâ”€â”€ notebooks/             # Jupyter notebooks for training
â”‚   â”œâ”€â”€ training_model.ipynb
â”‚   â””â”€â”€ sentiment_model.ipynb
â”œâ”€â”€ tools/                 # Development tools
â”‚   â”œâ”€â”€ convert_dataset.py
â”‚   â””â”€â”€ sentiment-env/     # Virtual environment
â”œâ”€â”€ sentiment_api.py       # FastAPI application
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md             # This file
```

## ğŸ§  Model Details

### Training Configuration
- **Vectorizer**: TF-IDF with max 1000 features, unigrams + bigrams
- **Model**: Logistic Regression with custom class weights
- **Class Weights**: {Negative: 5.0, Neutral: 1.0, Positive: 1.0}
- **Optimization**: Focused on negative comment detection

### Performance Metrics
- Accuracy: 88%
- Precision: 92%
- Recall (Negative): 96%
- F1-Score: 84%
- AUC: 95.6%

##  API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | API information |
| GET | `/health` | Health check |
| GET | `/docs` | Interactive documentation |
| POST | `/predict` | Single text prediction |
| POST | `/predict_bulk` | Multiple texts prediction |

## ğŸ› Troubleshooting
